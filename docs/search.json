{
  "articles": [
    {
      "path": "assignments.html",
      "title": "Assignments",
      "author": [],
      "contents": "\n\nContents\nWeek 1\nSlides:\nAssigned\nReading:\nLab:\n\nWeek 2\nSlides:\nAssigned\nReading:\nLab:\nDiscussion:\n\nWeek 3\nSlides:\nAssigned\nReading:\nLab:\nDiscussion:\n\n\n\nAssigned readings and labs will be posted to this page on a weekly\nbasis.\n\nWeek 1\nSlides:\nLecture 1: Course Welcome and\nIntro\nLecture 2: Linear\nRegression I\nAssigned Reading:\nHOML Ch.\n1 (1.1 - 1.4)\nSupplementary Reading\nGet Started\nwith TidyModels - Section 2.\nLab:\nLink\nto .Rmd\nWeek 2\nSlides:\nLecture 1: Model\nProcess and Ridge Regression\nLecture 2: Lab 2 -\nLinear Regression II\nAssigned Reading:\nHOML\nCh. 2\nHOML\nCh. 4 (4.2-4.5)\nReview of basic regression. Feel free to skim this a bit if you feel\ngood about your understanding of linear regression.\n\nSupplementary Reading\nTidy\nModels in R Ch. 3 (3.3-3.5)\nIntro to Tidy Modeling. Provides some context for Lab 1 and\nbeyond.\n\nLab:\nLink\nto .Rmd\nDiscussion:\nDownload discussion template here\nDownload discussion data here\nDownload completed discussion here\nWeek 3\nSlides:\nLecture: Classification\nand Logistic Regression\nAssigned Reading:\nHOML\nCh. 5, HOML\nCh. 6\nLab:\nDemo\nAssignment\nDiscussion:\nDownload completed discussion here\n\n\n\n",
      "last_modified": "2024-01-25T08:15:36-08:00"
    },
    {
      "path": "index.html",
      "title": "EDS 232: Machine Learning in Environmental Science",
      "description": "",
      "author": [],
      "contents": "\n\nContents\nWelcome to the EDS 232 website\nCourse description\nTeaching team\nImportant links\nWeekly course schedule\nLearning objectives\nCourse requirements\nComputing\nTextbook\n\n\nTentative topics\n\n\n\n\nFigure 1: Image created using the Midjourney image generation tool\n\n\n\nWelcome to the EDS 232 website\nCourse description\nMachine learning is a field of inquiry devoted to understanding and building methods that ‘learn’, that is, methods that leverage data to improve performance on some set of tasks. In this course, we focus on the core concepts of machine learning that beginning ML researchers must know. We cover ‘classical machine learning’ primarily using R, and explore applications to environmental science. To understand broader concepts of artificial intelligence or deep learning, a strong fundamental knowledge of machine learning is indispensable.\nTeaching team\nInstructor: Mateo Robbins (mjrobbins@ucsb.edu)\nStudent hours: Thursday 10:45-11:45pm (Location: Bren 1424)\nTeaching assistant: Allie Caughman (acaughman@bren.ucsb.edu)\nStudent hours: Tuesday 3:00-4:00pm (Location: Bren 3526)\nImportant links\nLink to full course syllabus\nWeekly course schedule\nLecture: TTh 9:30am - 10:45am PST (Bren 1424)\nSection:\nFirst 5 weeks: Th 2:00pm - 2:50pm, 3:00 - 3:50pm\n2/15 and onward: Th 12:30 - 1:20pm, 1:30 - 2:20pm\n\nLearning objectives\nThe goal of EDS 232 is to equip students with a strong foundation in the core concepts of machine learning. By the end of the course, students should be able to: \nBuild machine learning models in R using popular machine learning packages\nBuild and train supervised machine learning models for prediction and binary classification tasks, including linear and logistic regression.\nApply best practices for machine learning development so that your models generalize to data and tasks in the real world.\nBuild and use decision trees and tree ensemble methods, including random forests and boosted trees.\nUse unsupervised learning techniques including clustering.\nCourse requirements\nComputing\nMinimum MEDS device requirements\nR version 4.0.2 (or higher)\nRStudio version 1.4.1103 (or higher)\nTextbook\nHands-On Machine Learning with R, by Bradley Boehmke and Brandon Greenwell\n\nTentative topics\nWeek #\nDates\nLecture \n1\n1/9, 1/11\nIntroduction, Linear Regression and ML Modeling Fundamentals I\n2\n1/16, 1/18\nRegularized Regression and ML Modeling Fundamentals II\n3\n1/23, 1/25\nLogistic Regression, Classification\n4\n1/30, 2/1\nK-nearest neighbors, Decision Trees\n5\n2/6, 2/8\nBagging, Random Forest\n6\n2/13, 2/15\nGradient Boosting\n7\n2/20, 2/22\nClustering\n8\n2/27, 3/1\nTBD\n9\n3/6, 3/8\nTBD\n10\n3/13, 3/15\nKaggle\n\n\n\n",
      "last_modified": "2024-01-22T12:06:39-08:00"
    },
    {
      "path": "resources.html",
      "title": "Course resources",
      "author": [],
      "contents": "\n\nContents\nWeek 1\n\n\nTO UPDATE THIS PAGE: Open and edit the resources.Rmd file, in the project root, to delete this placeholder text and customize with your own!\n\nWeek 1\nLecture slides:\nAssignment:\n\n\n\n",
      "last_modified": "2024-01-22T12:05:37-08:00"
    }
  ],
  "collections": []
}
