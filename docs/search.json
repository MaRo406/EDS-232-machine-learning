[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning in Environmental Science",
    "section": "",
    "text": "Image created using the Midjourney image generation tool"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Machine Learning in Environmental Science",
    "section": "Course Description",
    "text": "Course Description\nMachine learning is a field of inquiry devoted to understanding and building methods that “learn,” that is, methods that leverage data to improve performance on some set of tasks. In this course, we focus on the core concepts of machine learning that beginning ML researchers must know. We cover “classical machine learning” primarily using R and explore applications to environmental science. To understand broader concepts of artificial intelligence or deep learning, a strong fundamental knowledge of machine learning is indispensable."
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Machine Learning in Environmental Science",
    "section": "Teaching Team",
    "text": "Teaching Team\nInstructor: Mateo Robbins (mjrobbins@ucsb.edu)\nStudent hours: Tuesdays 10:45am (Bren 1424)\nTeaching Assistant: Annie Adams (aradams@ucsb.edu)\nStudent hours: Thursdays 11:00am (Bren 3022)"
  },
  {
    "objectID": "index.html#important-links",
    "href": "index.html#important-links",
    "title": "Machine Learning in Environmental Science",
    "section": "Important Links",
    "text": "Important Links\n\nLink to full course syllabus"
  },
  {
    "objectID": "index.html#weekly-course-schedule",
    "href": "index.html#weekly-course-schedule",
    "title": "Machine Learning in Environmental Science",
    "section": "Weekly Course Schedule",
    "text": "Weekly Course Schedule\nLecture: TTh 9:30am - 10:45am (Bren 1424)\nSections: Th 1:00pm - 1:50pm or 2:00 - 2:50pm (Bren 3022)"
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Machine Learning in Environmental Science",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nThe goal of EDS 232 is to equip students with a strong foundation in the core concepts of machine learning. By the end of the course, students should be able to:\n\nExplain key machine learning concepts such as classification, regression, overfitting, and the trade-off in model complexity.\nIdentify and justify appropriate data preprocessing techniques and integrate them into machine learning pipelines.\nDemonstrate an intuitive understanding of common machine learning algorithms.\nBuild supervised machine learning pipelines using Python and scikit-learn on real-world datasets.\nApply best practices for machine learning development so that your models generalize to data and tasks in the real world. Measure and contrast the performance of various models"
  },
  {
    "objectID": "index.html#course-requirements",
    "href": "index.html#course-requirements",
    "title": "Machine Learning in Environmental Science",
    "section": "Course Requirements",
    "text": "Course Requirements\n\nComputing\n\nMinimum MEDS device requirements\n\n\n\nTextbook\n\nIntro to Statistical Learning with Python"
  },
  {
    "objectID": "index.html#course-topics",
    "href": "index.html#course-topics",
    "title": "Machine Learning in Environmental Science",
    "section": "Course Topics",
    "text": "Course Topics\n\n\n\n\n\n\n\n\nWeek #\nDates\nLecture\n\n\n1\n1/7, 1/9\nIntroduction, Linear Regression and ML Modeling Fundamentals I\n\n\n2\n1/14, 1/16\nRegularized Regression and ML Modeling Fundamentals II\n\n\n3\n1/21, 1/23\nLogistic Regression, Classification\n\n\n4\n1/28, 1/30\nK-nearest neighbors, Decision Trees\n\n\n5\n2/3, 2/6\nRandom Forest\n\n\n6\n2/11, 2/13\nGradient Boosting\n\n\n7\n2/18, 2/20\nClustering\n\n\n8\n2/25, 2/27\nSupport Vector Machines\n\n\n9\n3/4, 3/6\nDeep Learning\n\n\n10\n3/11, 3/13\nKaggle"
  },
  {
    "objectID": "labs/Lab3/Lab3.html",
    "href": "labs/Lab3/Lab3.html",
    "title": "Lab 3: Building a Spotify Song Classifier",
    "section": "",
    "text": "This week’s lab is a musical lab. You’ll be requesting data from the Spotify API and using it to build k-nearest neighbor and decision tree models.\nYou have two options for completing this lab.\nOption 1: Classify by users. Build models that predict whether a given song will be in your collection vs. a partner in class. This requires that you were already a Spotify user so you have enough data to work with. You will download your data from the Spotify API and then exchange with another member of class.\nOption 2: Classify by genres. Build models that predict which genre a song belongs to. This will use a pre-existing Spotify dataset available from Kaggle.com (https://www.kaggle.com/datasets/mrmorj/dataset-of-songs-in-spotify)"
  },
  {
    "objectID": "labs/Lab3/Lab3.html#option-1-classify-by-users",
    "href": "labs/Lab3/Lab3.html#option-1-classify-by-users",
    "title": "Lab 3: Building a Spotify Song Classifier",
    "section": "Option 1: Classify by Users",
    "text": "Option 1: Classify by Users"
  },
  {
    "objectID": "labs/Lab3/Lab3.html#step-1-setting-up-spotify-api",
    "href": "labs/Lab3/Lab3.html#step-1-setting-up-spotify-api",
    "title": "Lab 3: Building a Spotify Song Classifier",
    "section": "Step 1: Setting up Spotify API",
    "text": "Step 1: Setting up Spotify API\nIn order to use the Spotify API you must have a Spotify account. If you don’t have one, sign up for a free one here: https://www.spotify.com/us/signup\nOnce you have an account, go to Spotify for developers (https://developer.spotify.com/) and log in. Click the green “Create a Client ID” button to fill out the form to create an app create an app so you can access the API.\nOn your developer dashboard page, click on the new app you just created. On the app’s dashboard page you will find your Client ID just under the header name of your app. Click “Show Client Secret” to access your secondary Client ID. When you do this you’ll be issued a Spotify client ID and client secret key.\n\npip install spotipy\n\nThe history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\nCollecting spotipy\n  Downloading spotipy-2.24.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting redis&gt;=3.5.3 (from spotipy)\n  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: requests&gt;=2.25.0 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from spotipy) (2.32.3)\nRequirement already satisfied: urllib3&gt;=1.26.0 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.26.7)\nRequirement already satisfied: async-timeout&gt;=4.0.3 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from redis&gt;=3.5.3-&gt;spotipy) (4.0.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from requests&gt;=2.25.0-&gt;spotipy) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from requests&gt;=2.25.0-&gt;spotipy) (3.2)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from requests&gt;=2.25.0-&gt;spotipy) (2021.10.8)\nDownloading spotipy-2.24.0-py3-none-any.whl (30 kB)\nDownloading redis-5.2.0-py3-none-any.whl (261 kB)\nInstalling collected packages: redis, spotipy\nSuccessfully installed redis-5.2.0 spotipy-2.24.0\nNote: you may need to restart the kernel to use updated packages."
  },
  {
    "objectID": "labs/Lab3/Lab3.html#step-2-authentication",
    "href": "labs/Lab3/Lab3.html#step-2-authentication",
    "title": "Lab 3: Building a Spotify Song Classifier",
    "section": "Step 2: Authentication",
    "text": "Step 2: Authentication\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\n\n# Set your client ID and client secret\nsp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n    client_id='your_client_id',\n    client_secret='your_client_secret',\n    redirect_uri='http://localhost:8888/callback',\n    scope=\"user-library-read user-read-recently-played\"\n))"
  },
  {
    "objectID": "labs/Lab3/Lab3.html#step-3-data-collection",
    "href": "labs/Lab3/Lab3.html#step-3-data-collection",
    "title": "Lab 3: Building a Spotify Song Classifier",
    "section": "Step 3: Data Collection",
    "text": "Step 3: Data Collection\nYou can use fetch_tracks() and the sp.current_user_saved_tracks() method to request all your liked tracks. It would be good if you had at least 150-200 liked tracks so the model has enough data to work with. If you don’t have enough liked tracks, you can instead use sp.current_user_recently_played(), and in that case grab at least 500 recently played tracks if you can.\nThe Spotify API returns a dataframe of tracks and associated attributes. However, it will only return up to 50 (or 20) tracks at a time, so you will have to make multiple requests. Use a function to combine all your requests in one call.\nOnce you have your tracks, familiarize yourself with this initial dataframe. You’ll need to request some additional information for the analysis. If you give the API a list of track IDs using fetch_audio_features(), it will return an audio features dataframe of all the tracks and some attributes of them.\nCHECK THIS: These track audio features are the predictors we are interested in, but this dataframe doesn’t have the actual names of the tracks. Append the ‘track.name’ column from your favorite tracks database.\nFind a class mate whose data you would like to use. Add your partner’s data to your dataset. Create a new column that will contain the outcome variable that you will try to predict. This variable should contain two values that represent if the track came from your data set or your partner’s. Fetch your liked tracks or recently played tracks:\n\nimport pandas as pd\n\ndef fetch_tracks(sp, fetch_function, limit=50):\n    results = []\n    offset = 0\n    while True:\n        response = fetch_function(limit=limit, offset=offset)\n        items = response['items']\n        if not items:\n            break\n        results.extend(items)\n        offset += limit\n    return pd.DataFrame(results)\n\n# Fetch liked tracks\nliked_tracks = fetch_tracks(sp, sp.current_user_saved_tracks)\n\n# Fetch recently played tracks\nrecent_tracks = fetch_tracks(sp, sp.current_user_recently_played)\n\n\nGet audio features for tracks\n\ndef fetch_audio_features(sp, track_ids):\n    features = sp.audio_features(track_ids)\n    return pd.DataFrame(features)\n\n# Example: Fetch audio features for liked tracks\nliked_track_ids = liked_tracks['track'].apply(lambda x: x['id'])\naudio_features = fetch_audio_features(sp, liked_track_ids)\n\n\n\nCombine datasets with an outcome variable\n\n# Add track names for reference\naudio_features['track_name'] = liked_tracks['track'].apply(lambda x: x['name'])\n\n# Combine with another user's data\npartner_audio_features = ...  # Replace with partner's dataset\naudio_features['label'] = 'your_data'\npartner_audio_features['label'] = 'partner_data'\ncombined_data = pd.concat([audio_features, partner_audio_features])\n\n\n\nOption 2: Classify by Genres\n\nDownload and inspect Kaggle dataset:\n\n\nspotify_data = pd.read_csv('path_to_spotify_dataset.csv')\n\n# Filter down to two genres\ngenre_1_data = spotify_data[spotify_data['genre'] == 'Genre1']\ngenre_2_data = spotify_data[spotify_data['genre'] == 'Genre2']\ncombined_data = pd.concat([genre_1_data, genre_2_data])\ncombined_data['label'] = combined_data['genre']"
  },
  {
    "objectID": "labs/Lab3/Lab3.html#step-4-data-exploration",
    "href": "labs/Lab3/Lab3.html#step-4-data-exploration",
    "title": "Lab 3: Building a Spotify Song Classifier",
    "section": "Step 4: Data Exploration",
    "text": "Step 4: Data Exploration\nUse descriptive statistics and visualizations to explore the data.\n\nimport matplotlib.pyplot as plt\n\n# Example: Plot danceability\ncombined_data['danceability'].hist(by=combined_data['label'])\nplt.show()\n\n# Example: Compare energy levels\ncombined_data.boxplot(column='energy', by='label')\nplt.show()\n\nStep 5: Modeling 1. Preprocessing\n\nfrom sklearn.model_selection import train_test_split\n\nX = combined_data.drop(columns=['label', 'track_name', 'genre'])\ny = combined_data['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nDefine models\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n\n# KNN\nknn = KNeighborsClassifier()\n\n# Decision Tree\ndt = DecisionTreeClassifier(random_state=42)\n\n# Bagged Tree\nbagged_tree = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n\n# Random Forest\nrandom_forest = RandomForestClassifier(random_state=42)\n\n\nTrain and evaluate models\n\n\nfrom sklearn.metrics import classification_report, accuracy_score\n\nmodels = [knn, dt, bagged_tree, random_forest]\nmodel_names = ['KNN', 'Decision Tree', 'Bagged Tree', 'Random Forest']\n\nfor model, name in zip(models, model_names):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f\"--- {name} ---\")\n    print(classification_report(y_test, y_pred))\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n\nStep 6. Model Comparison Summarize the model performances in a table and create visualizations for comparison\n\nimport matplotlib.pyplot as plt\n\naccuracies = [accuracy_score(y_test, model.predict(X_test)) for model in models]\nplt.bar(model_names, accuracies)\nplt.ylabel('Accuracy')\nplt.title('Model Comparison')\nplt.show()"
  },
  {
    "objectID": "labs/Lab2/Untitled.html",
    "href": "labs/Lab2/Untitled.html",
    "title": "Step 1: Setting up Spotify API",
    "section": "",
    "text": "Create a Spotify account if you don’t already have one: Spotify Signup.\nGo to the Spotify Developer Dashboard and log in.\nClick “Create an App” to generate a Client ID and Client Secret.\nIn your app settings, add http://localhost:8888/callback as a redirect URI.\nInstall required spotipy library:\npip install spotipy\n\nThe history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\nCollecting spotipy\n  Downloading spotipy-2.24.0-py3-none-any.whl.metadata (4.9 kB)\nCollecting redis&gt;=3.5.3 (from spotipy)\n  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: requests&gt;=2.25.0 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from spotipy) (2.32.3)\nRequirement already satisfied: urllib3&gt;=1.26.0 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.26.7)\nRequirement already satisfied: async-timeout&gt;=4.0.3 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from redis&gt;=3.5.3-&gt;spotipy) (4.0.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from requests&gt;=2.25.0-&gt;spotipy) (2.0.4)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from requests&gt;=2.25.0-&gt;spotipy) (3.2)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages (from requests&gt;=2.25.0-&gt;spotipy) (2021.10.8)\nDownloading spotipy-2.24.0-py3-none-any.whl (30 kB)\nDownloading redis-5.2.0-py3-none-any.whl (261 kB)\nInstalling collected packages: redis, spotipy\nSuccessfully installed redis-5.2.0 spotipy-2.24.0\nNote: you may need to restart the kernel to use updated packages."
  },
  {
    "objectID": "labs/Lab2/Untitled.html#step-2-authentication",
    "href": "labs/Lab2/Untitled.html#step-2-authentication",
    "title": "Step 1: Setting up Spotify API",
    "section": "Step 2: Authentication",
    "text": "Step 2: Authentication\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\n\n# Set your client ID and client secret\nsp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n    client_id='your_client_id',\n    client_secret='your_client_secret',\n    redirect_uri='http://localhost:8888/callback',\n    scope=\"user-library-read user-read-recently-played\"\n))"
  },
  {
    "objectID": "labs/Lab2/Untitled.html#step-3-data-collection",
    "href": "labs/Lab2/Untitled.html#step-3-data-collection",
    "title": "Step 1: Setting up Spotify API",
    "section": "Step 3: Data Collection",
    "text": "Step 3: Data Collection\nOption 1: Classify by Users Fetch your liked tracks or recently played tracks:\n\nimport pandas as pd\n\ndef fetch_tracks(sp, fetch_function, limit=50):\n    results = []\n    offset = 0\n    while True:\n        response = fetch_function(limit=limit, offset=offset)\n        items = response['items']\n        if not items:\n            break\n        results.extend(items)\n        offset += limit\n    return pd.DataFrame(results)\n\n# Fetch liked tracks\nliked_tracks = fetch_tracks(sp, sp.current_user_saved_tracks)\n\n# Fetch recently played tracks\nrecent_tracks = fetch_tracks(sp, sp.current_user_recently_played)\n\n\nGet audio features for tracks\n\ndef fetch_audio_features(sp, track_ids):\n    features = sp.audio_features(track_ids)\n    return pd.DataFrame(features)\n\n# Example: Fetch audio features for liked tracks\nliked_track_ids = liked_tracks['track'].apply(lambda x: x['id'])\naudio_features = fetch_audio_features(sp, liked_track_ids)\n\n\n\nCombine datasets with an outcome variable\n\n# Add track names for reference\naudio_features['track_name'] = liked_tracks['track'].apply(lambda x: x['name'])\n\n# Combine with another user's data\npartner_audio_features = ...  # Replace with partner's dataset\naudio_features['label'] = 'your_data'\npartner_audio_features['label'] = 'partner_data'\ncombined_data = pd.concat([audio_features, partner_audio_features])\n\n\n\nOption 2: Classify by Genres\n\nDownload and inspect Kaggle dataset:\n\n\nspotify_data = pd.read_csv('path_to_spotify_dataset.csv')\n\n# Filter down to two genres\ngenre_1_data = spotify_data[spotify_data['genre'] == 'Genre1']\ngenre_2_data = spotify_data[spotify_data['genre'] == 'Genre2']\ncombined_data = pd.concat([genre_1_data, genre_2_data])\ncombined_data['label'] = combined_data['genre']"
  },
  {
    "objectID": "labs/Lab2/Untitled.html#step-4-data-exploration",
    "href": "labs/Lab2/Untitled.html#step-4-data-exploration",
    "title": "Step 1: Setting up Spotify API",
    "section": "Step 4: Data Exploration",
    "text": "Step 4: Data Exploration\nUse descriptive statistics and visualizations to explore the data.\n\nimport matplotlib.pyplot as plt\n\n# Example: Plot danceability\ncombined_data['danceability'].hist(by=combined_data['label'])\nplt.show()\n\n# Example: Compare energy levels\ncombined_data.boxplot(column='energy', by='label')\nplt.show()\n\nStep 5: Modeling 1. Preprocessing\n\nfrom sklearn.model_selection import train_test_split\n\nX = combined_data.drop(columns=['label', 'track_name', 'genre'])\ny = combined_data['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nDefine models\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n\n# KNN\nknn = KNeighborsClassifier()\n\n# Decision Tree\ndt = DecisionTreeClassifier(random_state=42)\n\n# Bagged Tree\nbagged_tree = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n\n# Random Forest\nrandom_forest = RandomForestClassifier(random_state=42)\n\n\nTrain and evaluate models\n\n\nfrom sklearn.metrics import classification_report, accuracy_score\n\nmodels = [knn, dt, bagged_tree, random_forest]\nmodel_names = ['KNN', 'Decision Tree', 'Bagged Tree', 'Random Forest']\n\nfor model, name in zip(models, model_names):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print(f\"--- {name} ---\")\n    print(classification_report(y_test, y_pred))\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n\nStep 6. Model Comparison Summarize the model performances in a table and create visualizations for comparison\n\nimport matplotlib.pyplot as plt\n\naccuracies = [accuracy_score(y_test, model.predict(X_test)) for model in models]\nplt.bar(model_names, accuracies)\nplt.ylabel('Accuracy')\nplt.title('Model Comparison')\nplt.show()"
  },
  {
    "objectID": "labs/Lab1/dist-lab1/student/Lab1_template.html",
    "href": "labs/Lab1/dist-lab1/student/Lab1_template.html",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "# Initialize Otter\nimport otter\ngrader = otter.Notebook(\"Lab1_template.ipynb\")"
  },
  {
    "objectID": "labs/Lab1/dist-lab1/student/Lab1_template.html#general-lab-template",
    "href": "labs/Lab1/dist-lab1/student/Lab1_template.html#general-lab-template",
    "title": "EDS232 Lab 1: Regression",
    "section": "General Lab Template",
    "text": "General Lab Template\n\nLook at the big picture.\nGet the data.\nExplore and visualize the data to gain insights.\nPrepare the data for machine learning algorithms.\nSelect a model and train it.\nFine-tune your model.\nPresent your solution."
  },
  {
    "objectID": "labs/Lab1/dist-lab1/student/Lab1_template.html#overview",
    "href": "labs/Lab1/dist-lab1/student/Lab1_template.html#overview",
    "title": "EDS232 Lab 1: Regression",
    "section": "Overview",
    "text": "Overview\nIn this lab, we will introduce the basics of machine learning in Python by focusing on regression, a core technique used to predict continuous outcomes. We will use the popular scikit-learn library, which provides easy-to-use tools for building and evaluating machine learning models. Specifically, we will focus on how regression algorithms can help us model and predict water quality data."
  },
  {
    "objectID": "labs/Lab1/dist-lab1/student/Lab1_template.html#objectives",
    "href": "labs/Lab1/dist-lab1/student/Lab1_template.html#objectives",
    "title": "EDS232 Lab 1: Regression",
    "section": "Objectives",
    "text": "Objectives\nBy the end of this lab, you will be able to: - Understand the concept of regression and its implementation in Pythnon - Implement simple and multiple linear regression models - Evaluate model performance using various metrics like R², MSE, and RMSE - Visualize regression prediction results"
  },
  {
    "objectID": "labs/Lab1/dist-lab1/student/Lab1_template.html#key-concepts",
    "href": "labs/Lab1/dist-lab1/student/Lab1_template.html#key-concepts",
    "title": "EDS232 Lab 1: Regression",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nMachine Learning: A subset of artificial intelligence where algorithms learn patterns from data to make predictions or decisions without being explicitly programmed.\nRegression: A machine learning method for predicting continuous values.\n\nSimple Linear Regression: A regression model with one independent variable.\nMultiple Linear Regression: A regression model with two or more independent variables.\n\nScikit-learn: A Python library that provides simple and efficient tools for data mining and machine learning. We will use it for:\n\nData Preprocessing: Preparing data for the model.\nModel Training: Fitting the regression model to our data.\nModel Evaluation: Assessing model performance using model evaluation metrics\n\nModel Evaluation Metrics: Tools to assess how well our model fits the data, such as:\n\nR² (R-squared): Measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\nMAE (Mean Absolute Error): The average of the absolute differences between predicted and actual values.\nRMSE (Root Mean Square Error): The square root of the average squared differences between predicted and actual values.\n\n\n\nStep 1: Import libraries and load data\n\nAbout the data\n\nWe will be working with data regarding water quality in the Hudson River during and after Hurricane Irene in 2011. This dataset contains obesrvations in 15 minute increments over a span of 10 days. Measurements observed includ rainfall, depth, turbidity, water temperature, and dissolved oxygen. The data come from the Cary Institute and can be found here.\nNotice that the data is not a csv file and is instead a .xlsx file! Use the pandas.read_excel function to read in your data. You can find more documentation on reading in .xlsx files here.\nIn this lab, we are interested in the turbidity and dissolved oxygen variables. Read the data into the hurricane_do and hurricane_turbidity variables. Then, merge these two dataframes. Store the result in the df variable. Drop the columns that contain data for Piedmont. We are only interested in the Port of Albany and Norrie Point.\n\n\n\nLoad libraries\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport sklearn.linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\n\ndf.columns\n\n\nhurricane_do = ...\nhurricane_turbidity = ...\ndf = ...\n\n\ngrader.check(\"q1\")\n\n\n\n\nStep 2: Explore and clean the data\nDo some initial exploratory analysis on the data. Check out what type of data you are working with, and create a few plots of your data. Write a few sentences on your findings.\n\n# Explore and Visualize data \n# ex: scatterplot, correlation matrix\ndf[' Port of Albany Turbidity in NTU'].hist()\nplt.title('Histogram of Turbidity')\nplt.xlabel('Turbidity (NTU)')\nplt.ylabel('Frequency')\nplt.show()\n\ndf[' Port of Albany D.O. (ppm)'].hist()\nplt.title('Histogram of Dissolved Oxygen')\nplt.xlabel('Dissolved Oxygen (ppm)')\nplt.ylabel('Frequency')\nplt.show()\n\nUpdate this markdown cell with your findings.\nWhen you were exploring the data, you may have noticed that the column names aren’t the cleanest. Update the column names to the following : date, albany_DO, norrie_DO, albany_turbidity, norrie_turbidity.\n\ndf # Check to make sure column names were updated\n\n\ngrader.check(\"q2\")\n\n\n\nStep 3: Prepare the data for Machine Learning\nIt is time to split our data into training and testing data for our linear regression model. Split your training and testing data where albany_DO is your predictor variable and albany_turbidity is you response variable.\n\n# Select features and target\nX = ...\nY = ...\n\n\nX_train, X_test, Y_train, Y_test = ...\n\n\ngrader.check(\"q3\")\n\n\n\nStep 4: Select your model\nWe are going to use linear regression to predict the whole weight of oysters. Is linear regression a good model to pick to achieve this goal? Answer in the markdown cell below.\nYour answer here.\n\n# Initialize and fit the model\nmodel = ...\n\n\ngrader.check(\"q4\")\n\n\n\nStep 5: Evaluate the model\n\nMake predictions with your model and check the performance of the model after.\nCheck how your model perfromed by look at the mean squared error and the \\(R^2\\) score.\nCreate a scatter plot of the Y predictions and your Y test data.\n\n\n# Make predictions\nY_pred = ...\n\n# Calculate evaluation metrics using scikit-learn's mean_squared_error and r2_score\nmse = ...\nr2 = ...\n\nprint(f\"Mean Squared Error: {mse}\")\nprint(f\"R² Score: {r2}\")\n\n#Visualize predictions vs. actual values\n\n\ngrader.check(\"q5\")\n\n\n\nStep 6: Fine tune the model\nGet the cross validation score to see how your model performed across the different folds. In the markdown cell below, explain what cross valiadtion is and what the cross validation score represents.\nType your answer here.\n\n\n#Use cross_val_score() to fine-tune the model\nscores = cross_val_score(model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\nprint(f\"Cross-validation scores: {-scores}\")\n\n\ngrader.check(\"q6\")\n\n\n\nStep 7: Present the Solution\nIn the markdown cell below, discuss how your model performed overall. If the model performed poorly, why do you think it did so? If it performed well, why do you think it did so? What could future analysis include?\nYour answer here.\n\n\nBefore we ran our model, we should have first looked at the data to see if there was a lienar relationship between our variables.Let’s check now!\n\nplt.figure(figsize=(10, 6))  # Setting the figure size for better visibility\ndf.plot.scatter(x='albany_DO', y='albany_turbidity', c='DarkBlue')\n\nplt.title('Turbidity vs. Dissolved Oxygen at Port of Albany')\nplt.xlabel('Dissolved Oxygen (ppm)')\nplt.ylabel('Turbidity (NTU)')\nplt.grid(True)\nplt.show()\n\n\n\nStep 8: Check to see if polynomial regression performs better\nWe assumed linear regression would work best with our data, but lets check to see how a polynomial regression performs in comparison. Transform the features for polynomial regression. Use the PolynomialFeatures library from sklearn.preprocessing.\n\n# Transform features to include polynomial terms (degree 2 for quadratic terms)\npoly = ...\nX_poly_train = ...\nX_poly_test = ...\n\n# View the transformed feature set (for insight)\nprint(X_poly_train)\n\n\n\nStep 9: Fit your model on the polynomial features\n\n# Train the model on polynomial features \npoly_model = ...\n\n\n\nSTEP 10: Evaluate the polynomial regression model\n\nMake predictions with your model and check the performance of the model after.\nCheck how your model perfromed by look at the mean squared error and the \\(R^2\\) score.\nCreate a scatter plot of the Y polynomial predictions and your Y test data.\n\n\n# Make predictions using the polynomial model\nY_poly_pred = ...\n\n# Calculate evaluation metrics using scikit-learn's mean_squared_error and r2_score\npoly_mse = ...\npoly_r2 = ...\n\nprint(f\"Polynomial Regression Mean Squared Error: {poly_mse}\")\nprint(f\"Polynomial Regression R² Score: {poly_r2}\")\n\n# Plot predictions vs actual\n\n\ngrader.check(\"q10\")\n\n\n\nStep 11: Compare your polynomial and linear regression results\nWhat differences did you notice between you polynomial regression and linear regression results? Which model performed better? Why do you think this is? Write your answer in the markdown cell below.\nYour answer here."
  },
  {
    "objectID": "labs/Lab1/dist-lab1/autograder/Lab1_template.html",
    "href": "labs/Lab1/dist-lab1/autograder/Lab1_template.html",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "# Initialize Otter\nimport otter\ngrader = otter.Notebook(\"Lab1_template.ipynb\")"
  },
  {
    "objectID": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#general-lab-template",
    "href": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#general-lab-template",
    "title": "EDS232 Lab 1: Regression",
    "section": "General Lab Template",
    "text": "General Lab Template\n\nLook at the big picture.\nGet the data.\nExplore and visualize the data to gain insights.\nPrepare the data for machine learning algorithms.\nSelect a model and train it.\nFine-tune your model.\nPresent your solution."
  },
  {
    "objectID": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#overview",
    "href": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#overview",
    "title": "EDS232 Lab 1: Regression",
    "section": "Overview",
    "text": "Overview\nIn this lab, we will introduce the basics of machine learning in Python by focusing on regression, a core technique used to predict continuous outcomes. We will use the popular scikit-learn library, which provides easy-to-use tools for building and evaluating machine learning models. Specifically, we will focus on how regression algorithms can help us model and predict water quality data."
  },
  {
    "objectID": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#objectives",
    "href": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#objectives",
    "title": "EDS232 Lab 1: Regression",
    "section": "Objectives",
    "text": "Objectives\nBy the end of this lab, you will be able to: - Understand the concept of regression and its implementation in Pythnon - Implement simple and multiple linear regression models - Evaluate model performance using various metrics like R², MSE, and RMSE - Visualize regression prediction results"
  },
  {
    "objectID": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#key-concepts",
    "href": "labs/Lab1/dist-lab1/autograder/Lab1_template.html#key-concepts",
    "title": "EDS232 Lab 1: Regression",
    "section": "Key Concepts",
    "text": "Key Concepts\n\nMachine Learning: A subset of artificial intelligence where algorithms learn patterns from data to make predictions or decisions without being explicitly programmed.\nRegression: A machine learning method for predicting continuous values.\n\nSimple Linear Regression: A regression model with one independent variable.\nMultiple Linear Regression: A regression model with two or more independent variables.\n\nScikit-learn: A Python library that provides simple and efficient tools for data mining and machine learning. We will use it for:\n\nData Preprocessing: Preparing data for the model.\nModel Training: Fitting the regression model to our data.\nModel Evaluation: Assessing model performance using model evaluation metrics\n\nModel Evaluation Metrics: Tools to assess how well our model fits the data, such as:\n\nR² (R-squared): Measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\nMAE (Mean Absolute Error): The average of the absolute differences between predicted and actual values.\nRMSE (Root Mean Square Error): The square root of the average squared differences between predicted and actual values.\n\n\n\nStep 1: Import libraries and load data\n\nAbout the data\n\nWe will be working with data regarding water quality in the Hudson River during and after Hurricane Irene in 2011. This dataset contains obesrvations in 15 minute increments over a span of 10 days. Measurements observed includ rainfall, depth, turbidity, water temperature, and dissolved oxygen. The data come from the Cary Institute and can be found here.\nNotice that the data is not a csv file and is instead a .xlsx file! Use the pandas.read_excel function to read in your data. You can find more documentation on reading in .xlsx files here.\nIn this lab, we are interested in the turbidity and dissolved oxygen variables. Read the data into the hurricane_do and hurricane_turbidity variables. Then, merge these two dataframes. Store the result in the df variable. Drop the columns that contain data for Piedmont. We are only interested in the Port of Albany and Norrie Point.\n\n\n\nLoad libraries\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport sklearn.linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\n\n\ndf.columns\n\nIndex(['date', 'albany_DO', 'albany_turbidity', 'piedmont_DO',\n       'piedmont_turbidity'],\n      dtype='object')\n\n\n\nhurricane_do = pd.read_excel('data/Hurricane_Irene_Hudson_River.xlsx', sheet_name = 5) # SOLUTION\nhurricane_turbidity = pd.read_excel('data/Hurricane_Irene_Hudson_River.xlsx', sheet_name = 2) # SOLUTION\ndf = hurricane_do.merge(hurricane_turbidity, on = 'Date Time (ET)').drop(['Piermont D.O. (ppm)', 'Piermont Turbidity in NTU'], axis = 1) # SOLUTION\n\n\ngrader.check(\"q1\")\n\n\n\n\nStep 2: Explore and clean the data\nDo some initial exploratory analysis on the data. Check out what type of data you are working with, and create a few plots of your data. Write a few sentences on your findings.\n\n# Explore and Visualize data \n# ex: scatterplot, correlation matrix\ndf[' Port of Albany Turbidity in NTU'].hist()\nplt.title('Histogram of Turbidity')\nplt.xlabel('Turbidity (NTU)')\nplt.ylabel('Frequency')\nplt.show()\n\ndf[' Port of Albany D.O. (ppm)'].hist()\nplt.title('Histogram of Dissolved Oxygen')\nplt.xlabel('Dissolved Oxygen (ppm)')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdate this markdown cell with your findings.\nWhen you were exploring the data, you may have noticed that the column names aren’t the cleanest. Update the column names to the following : date, albany_DO, norrie_DO, albany_turbidity, norrie_turbidity.\n\ndf.columns = ['date', 'albany_DO', 'norrie_DO', 'albany_turbidity', 'norrie_turbidity'] # SOLUTION NO PROMPT\ndf # Check to make sure column names were updated\n\n\n\n\n\n\n\n\ndate\nalbany_DO\nnorrie_DO\nalbany_turbidity\nnorrie_turbidity\n\n\n\n\n0\n2011-08-25 00:00:00\n7.68\n7.81\n4.0\n9.3\n\n\n1\n2011-08-25 00:15:00\n7.60\n7.73\n3.9\n8.4\n\n\n2\n2011-08-25 00:30:00\n7.57\n7.63\n4.3\n7.9\n\n\n3\n2011-08-25 00:45:00\n7.72\n7.67\n4.7\n8.1\n\n\n4\n2011-08-25 01:00:00\n7.74\n7.63\n4.4\n8.4\n\n\n...\n...\n...\n...\n...\n...\n\n\n1147\n2011-09-05 22:45:00\n8.73\n6.84\n47.2\n144.1\n\n\n1148\n2011-09-05 23:00:00\n8.76\n6.78\n56.7\n139.7\n\n\n1149\n2011-09-05 23:15:00\n8.66\n6.83\n47.0\n141.2\n\n\n1150\n2011-09-05 23:30:00\n8.75\n6.79\n48.7\n127.9\n\n\n1151\n2011-09-05 23:45:00\n8.68\n6.78\n49.5\n149.0\n\n\n\n\n1152 rows × 5 columns\n\n\n\n\ngrader.check(\"q2\")\n\n\n\nStep 3: Prepare the data for Machine Learning\nIt is time to split our data into training and testing data for our linear regression model. Split your training and testing data where albany_DO is your predictor variable and albany_turbidity is you response variable.\n\n# Select features and target\nX = df[['albany_DO']] # SOLUTION\nY = df['albany_turbidity'] # SOLUTION\n\n\nX_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.33, random_state=42) # SOLUTION \n\n\ngrader.check(\"q3\")\n\n\n\nStep 4: Select your model\nWe are going to use linear regression to predict the whole weight of oysters. Is linear regression a good model to pick to achieve this goal? Answer in the markdown cell below.\nYour answer here.\n\n# Initialize and fit the model\nmodel = LinearRegression() # SOLUTION \nmodel.fit(X_train, Y_train) # SOLUTION NO PROMPT\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\n\ngrader.check(\"q4\")\n\n\n\nStep 5: Evaluate the model\n\nMake predictions with your model and check the performance of the model after.\nCheck how your model perfromed by look at the mean squared error and the \\(R^2\\) score.\nCreate a scatter plot of the Y predictions and your Y test data.\n\n\n# Make predictions\nY_pred = model.predict(X_test) # SOLUTION \n\n# Calculate evaluation metrics using scikit-learn's mean_squared_error and r2_score\nmse = mean_squared_error(Y_test, Y_pred) # SOLUTION\nr2 = r2_score(Y_test, Y_pred) # SOLUTION\n\nprint(f\"Mean Squared Error: {mse}\")\nprint(f\"R² Score: {r2}\")\n\n#Visualize predictions vs. actual values\nplt.scatter(Y_test, Y_pred) # SOLUTION NO PROMPT\nplt.xlabel('Actual') # SOLUTION NO PROMPT\nplt.ylabel('Predicted') # SOLUTION NO PROMPT\nplt.title('Actual vs Predicted') # SOLUTION NO PROMPT\nplt.show() # SOLUTION NO PROMPT\n\nMean Squared Error: 48731.6947400043\nR² Score: 0.4896381383344557\n\n\n\n\n\n\n\n\n\n\ngrader.check(\"q5\")\n\n\n\nStep 6: Fine tune the model\nGet the cross validation score to see how your model performed across the different folds. In the markdown cell below, explain what cross valiadtion is and what the cross validation score represents.\nType your answer here.\n\n\n#Use cross_val_score() to fine-tune the model\nscores = cross_val_score(model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\nprint(f\"Cross-validation scores: {-scores}\")\n\nCross-validation scores: [54698.71458122 50247.53217975 51966.65102117 40189.010764\n 46076.16681613]\n\n\n\ngrader.check(\"q6\")\n\n\n\nStep 7: Present the Solution\nIn the markdown cell below, discuss how your model performed overall. If the model performed poorly, why do you think it did so? If it performed well, why do you think it did so? What could future analysis include?\nYour answer here.\n\n\nBefore we ran our model, we should have first looked at the data to see if there was a lienar relationship between our variables.Let’s check now!\n\nplt.figure(figsize=(10, 6))  # Setting the figure size for better visibility\ndf.plot.scatter(x='albany_DO', y='albany_turbidity', c='DarkBlue')\n\nplt.title('Turbidity vs. Dissolved Oxygen at Port of Albany')\nplt.xlabel('Dissolved Oxygen (ppm)')\nplt.ylabel('Turbidity (NTU)')\nplt.grid(True)\nplt.show()\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nStep 8: Check to see if polynomial regression performs better\nWe assumed linear regression would work best with our data, but lets check to see how a polynomial regression performs in comparison. Transform the features for polynomial regression. Use the PolynomialFeatures library from sklearn.preprocessing.\n\n# Transform features to include polynomial terms (degree 2 for quadratic terms)\npoly = PolynomialFeatures(degree=2) # SOLUTION\nX_poly_train = poly.fit_transform(X_train) # SOLUTION\nX_poly_test = poly.transform(X_test) # SOLUTION\n\n# View the transformed feature set (for insight)\nprint(X_poly_train)\n\n[[ 1.      7.92   62.7264]\n [ 1.      9.     81.    ]\n [ 1.      9.7    94.09  ]\n ...\n [ 1.      8.75   76.5625]\n [ 1.      9.09   82.6281]\n [ 1.      8.6    73.96  ]]\n\n\n\n\nStep 9: Fit your model on the polynomial features\n\n# Train the model on polynomial features \npoly_model = LinearRegression() # SOLUTION\npoly_model.fit(X_poly_train, Y_train) # SOLUTION NO PROMPT\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\n\n\nSTEP 10: Evaluate the polynomial regression model\n\nMake predictions with your model and check the performance of the model after.\nCheck how your model perfromed by look at the mean squared error and the \\(R^2\\) score.\nCreate a scatter plot of the Y polynomial predictions and your Y test data.\n\n\n# Make predictions using the polynomial model\nY_poly_pred = poly_model.predict(X_poly_test) # SOLUTION\n\n# Calculate evaluation metrics using scikit-learn's mean_squared_error and r2_score\npoly_mse = mean_squared_error(Y_test, Y_poly_pred) # SOLUTION\npoly_r2 = r2_score(Y_test, Y_poly_pred) # SOLUTION\n\nprint(f\"Polynomial Regression Mean Squared Error: {poly_mse}\")\nprint(f\"Polynomial Regression R² Score: {poly_r2}\")\n\n# Plot predictions vs actual\nplt.scatter(Y_test, Y_poly_pred) # SOLUTION NO PROMPT\nplt.xlabel('Actual') # SOLUTION NO PROMPT\nplt.ylabel('Predicted') # SOLUTION NO PROMPT\nplt.title('Polynomial Regression: Actual vs Predicted') # SOLUTION NO PROMPT\nplt.show() # SOLUTION NO PROMPT\n\nPolynomial Regression Mean Squared Error: 24159.54013290374\nPolynomial Regression R² Score: 0.7469797029428922\n\n\n\n\n\n\n\n\n\n\ngrader.check(\"q10\")\n\n\n\nStep 11: Compare your polynomial and linear regression results\nWhat differences did you notice between you polynomial regression and linear regression results? Which model performed better? Why do you think this is? Write your answer in the markdown cell below.\nYour answer here."
  },
  {
    "objectID": "labs/Lab1/Lab1_template.html",
    "href": "labs/Lab1/Lab1_template.html",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "generate: true export_cell: false files: - data tests: files: true check_all_cell: false seed:\nautograder_value: 42\n\n\n\nLook at the big picture.\nGet the data.\nExplore and visualize the data to gain insights.\nPrepare the data for machine learning algorithms.\nSelect a model and train it.\nFine-tune your model.\nPresent your solution.\n\n\n\n\nIn this lab, we will introduce the basics of machine learning in Python by focusing on regression, a core technique used to predict continuous outcomes. We will use the popular scikit-learn library, which provides easy-to-use tools for building and evaluating machine learning models. Specifically, we will focus on how regression algorithms can help us model and predict water quality data.\n\n\n\nBy the end of this lab, you will be able to: - Understand the concept of regression and its implementation in Pythnon - Implement simple and multiple linear regression models - Evaluate model performance using various metrics like R², MSE, and RMSE - Visualize regression prediction results\n\n\n\n\nMachine Learning: A subset of artificial intelligence where algorithms learn patterns from data to make predictions or decisions without being explicitly programmed.\nRegression: A machine learning method for predicting continuous values.\n\nSimple Linear Regression: A regression model with one independent variable.\nMultiple Linear Regression: A regression model with two or more independent variables.\n\nScikit-learn: A Python library that provides simple and efficient tools for data mining and machine learning. We will use it for:\n\nData Preprocessing: Preparing data for the model.\nModel Training: Fitting the regression model to our data.\nModel Evaluation: Assessing model performance using model evaluation metrics\n\nModel Evaluation Metrics: Tools to assess how well our model fits the data, such as:\n\nR² (R-squared): Measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\nMAE (Mean Absolute Error): The average of the absolute differences between predicted and actual values.\nRMSE (Root Mean Square Error): The square root of the average squared differences between predicted and actual values.\n\n\n\n\n\n\n\nWe will be working with data regarding water quality in the Hudson River during and after Hurricane Irene in 2011. This dataset contains obesrvations in 15 minute increments over a span of 10 days. Measurements observed includ rainfall, depth, turbidity, water temperature, and dissolved oxygen. The data come from the Cary Institute and can be found here.\nNotice that the data is not a csv file and is instead a .xlsx file! Use the pandas.read_excel function to read in your data. You can find more documentation on reading in .xlsx files here.\nIn this lab, we are interested in the turbidity and dissolved oxygen variables. Read the data into the hurricane_do and hurricane_turbidity variables. Then, merge these two dataframes. Store the result in the df variable. Drop the columns that contain data for Piedmont. We are only interested in the Port of Albany and Norrie Point.\n\n\n\n\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport sklearn.linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures"
  },
  {
    "objectID": "labs/Lab1/Lab1_template.html#general-lab-template",
    "href": "labs/Lab1/Lab1_template.html#general-lab-template",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "Look at the big picture.\nGet the data.\nExplore and visualize the data to gain insights.\nPrepare the data for machine learning algorithms.\nSelect a model and train it.\nFine-tune your model.\nPresent your solution."
  },
  {
    "objectID": "labs/Lab1/Lab1_template.html#overview",
    "href": "labs/Lab1/Lab1_template.html#overview",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "In this lab, we will introduce the basics of machine learning in Python by focusing on regression, a core technique used to predict continuous outcomes. We will use the popular scikit-learn library, which provides easy-to-use tools for building and evaluating machine learning models. Specifically, we will focus on how regression algorithms can help us model and predict water quality data."
  },
  {
    "objectID": "labs/Lab1/Lab1_template.html#objectives",
    "href": "labs/Lab1/Lab1_template.html#objectives",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "By the end of this lab, you will be able to: - Understand the concept of regression and its implementation in Pythnon - Implement simple and multiple linear regression models - Evaluate model performance using various metrics like R², MSE, and RMSE - Visualize regression prediction results"
  },
  {
    "objectID": "labs/Lab1/Lab1_template.html#key-concepts",
    "href": "labs/Lab1/Lab1_template.html#key-concepts",
    "title": "EDS232 Lab 1: Regression",
    "section": "",
    "text": "Machine Learning: A subset of artificial intelligence where algorithms learn patterns from data to make predictions or decisions without being explicitly programmed.\nRegression: A machine learning method for predicting continuous values.\n\nSimple Linear Regression: A regression model with one independent variable.\nMultiple Linear Regression: A regression model with two or more independent variables.\n\nScikit-learn: A Python library that provides simple and efficient tools for data mining and machine learning. We will use it for:\n\nData Preprocessing: Preparing data for the model.\nModel Training: Fitting the regression model to our data.\nModel Evaluation: Assessing model performance using model evaluation metrics\n\nModel Evaluation Metrics: Tools to assess how well our model fits the data, such as:\n\nR² (R-squared): Measures the proportion of variance in the dependent variable that is predictable from the independent variable(s).\nMAE (Mean Absolute Error): The average of the absolute differences between predicted and actual values.\nRMSE (Root Mean Square Error): The square root of the average squared differences between predicted and actual values.\n\n\n\n\n\n\n\nWe will be working with data regarding water quality in the Hudson River during and after Hurricane Irene in 2011. This dataset contains obesrvations in 15 minute increments over a span of 10 days. Measurements observed includ rainfall, depth, turbidity, water temperature, and dissolved oxygen. The data come from the Cary Institute and can be found here.\nNotice that the data is not a csv file and is instead a .xlsx file! Use the pandas.read_excel function to read in your data. You can find more documentation on reading in .xlsx files here.\nIn this lab, we are interested in the turbidity and dissolved oxygen variables. Read the data into the hurricane_do and hurricane_turbidity variables. Then, merge these two dataframes. Store the result in the df variable. Drop the columns that contain data for Piedmont. We are only interested in the Port of Albany and Norrie Point.\n\n\n\n\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport sklearn.linear_model\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import PolynomialFeatures"
  },
  {
    "objectID": "labs/Lab2/Lab2 Regularized Regression.html",
    "href": "labs/Lab2/Lab2 Regularized Regression.html",
    "title": "EDS232 Lab 2: Regularized Regression",
    "section": "",
    "text": "In this lab, you will explore Ridge Regression and Lasso Regression, two common techniques for regularized regression. Both methods add penalties to the regression coefficients, which can help prevent overfitting and improve model interpretability. We will also apply the one-standard-error rule for Lasso regression to select a simpler model."
  },
  {
    "objectID": "labs/Lab2/Lab2 Regularized Regression.html#overview",
    "href": "labs/Lab2/Lab2 Regularized Regression.html#overview",
    "title": "EDS232 Lab 2: Regularized Regression",
    "section": "",
    "text": "In this lab, you will explore Ridge Regression and Lasso Regression, two common techniques for regularized regression. Both methods add penalties to the regression coefficients, which can help prevent overfitting and improve model interpretability. We will also apply the one-standard-error rule for Lasso regression to select a simpler model."
  },
  {
    "objectID": "labs/Lab2/Lab2 Regularized Regression.html#objectives",
    "href": "labs/Lab2/Lab2 Regularized Regression.html#objectives",
    "title": "EDS232 Lab 2: Regularized Regression",
    "section": "Objectives",
    "text": "Objectives\nBy the end of this lab, you will: - Implement Ridge and Lasso regression with cross-validation. - Compare the performance of Ridge and Lasso models. - Interpret model coefficients and understand their regularization effects. - Apply the one-standard-error rule to select a parsimonious Lasso model."
  },
  {
    "objectID": "labs/Lab2/Lab2 Regularized Regression.html#key-concepts",
    "href": "labs/Lab2/Lab2 Regularized Regression.html#key-concepts",
    "title": "EDS232 Lab 2: Regularized Regression",
    "section": "Key Concepts",
    "text": "Key Concepts\nWhat is Regularized Regression? - Regularized regression techniques are used to improve model generalization and prevent overfitting by adding a penalty term to the loss function of linear regression. - These methods are particularly useful for datasets with: - A large number of predictors. - High multicollinearity among predictors. - A tendency to overfit due to a small number of observations.\nTypes of Regularization:\n\nRidge Regression:\n\nAdds an L2 penalty ($_{j=1}^p _j^2 $) to the regression loss function.\nShrinks coefficients toward zero but does not set any coefficients exactly to zero.\nBest suited for reducing multicollinearity and improving model stability.\n\nLasso Regression:\n\nAdds an L1 penalty (\\(\\lambda \\sum_{j=1}^p |\\beta_j|\\)) to the regression loss function.\nCan shrink some coefficients to exactly zero, effectively performing feature selection.\nUseful when you want a simpler, interpretable model.\n\n\n\nAbout the data\n\nWe will be working with data dealing with physical abalone features. This dataset has observations of more than 4,000 abalone, measuring their length, diameter, height, and different rings. The data can be found here : https://archive.ics.uci.edu/dataset/1/abalone.\nNotice that the data is not a csv file and is instead a .data file! The .data file does not contain any column names, so we therefore need to specify the column names when we read our data in using pd.read_csv. Look at the metadata and assign column names to the data. When you are finished, look at the head of the dataframe to ensure it looks correct.\n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression \nfrom ucimlrepo import fetch_ucirepo\nimport kagglehub\n\n\n# Fetch dataset\nenergy_efficiency = fetch_ucirepo(id=242)\nenergy_efficiency.data\n\n{'ids': None,\n 'features':        X1     X2     X3      X4   X5  X6   X7  X8\n 0    0.98  514.5  294.0  110.25  7.0   2  0.0   0\n 1    0.98  514.5  294.0  110.25  7.0   3  0.0   0\n 2    0.98  514.5  294.0  110.25  7.0   4  0.0   0\n 3    0.98  514.5  294.0  110.25  7.0   5  0.0   0\n 4    0.90  563.5  318.5  122.50  7.0   2  0.0   0\n ..    ...    ...    ...     ...  ...  ..  ...  ..\n 763  0.64  784.0  343.0  220.50  3.5   5  0.4   5\n 764  0.62  808.5  367.5  220.50  3.5   2  0.4   5\n 765  0.62  808.5  367.5  220.50  3.5   3  0.4   5\n 766  0.62  808.5  367.5  220.50  3.5   4  0.4   5\n 767  0.62  808.5  367.5  220.50  3.5   5  0.4   5\n \n [768 rows x 8 columns],\n 'targets':         Y1     Y2\n 0    15.55  21.33\n 1    15.55  21.33\n 2    15.55  21.33\n 3    15.55  21.33\n 4    20.84  28.28\n ..     ...    ...\n 763  17.88  21.40\n 764  16.54  16.88\n 765  16.44  17.11\n 766  16.48  16.61\n 767  16.64  16.03\n \n [768 rows x 2 columns],\n 'original':        X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n 0    0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n 1    0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n 2    0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n 3    0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n 4    0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28\n ..    ...    ...    ...     ...  ...  ..  ...  ..    ...    ...\n 763  0.64  784.0  343.0  220.50  3.5   5  0.4   5  17.88  21.40\n 764  0.62  808.5  367.5  220.50  3.5   2  0.4   5  16.54  16.88\n 765  0.62  808.5  367.5  220.50  3.5   3  0.4   5  16.44  17.11\n 766  0.62  808.5  367.5  220.50  3.5   4  0.4   5  16.48  16.61\n 767  0.62  808.5  367.5  220.50  3.5   5  0.4   5  16.64  16.03\n \n [768 rows x 10 columns],\n 'headers': Index(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y1', 'Y2'], dtype='object')}\n\n\n\n\nExplore the data\nData Splitting Question 1: Split the data into training and test sets using a 70/30 split.\n\n# Assign predictor and outcome variables \nX = energy_efficiency.data.features\nY = energy_efficiency.data.targets['Y1']\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n\nRidge Regression Question 2 & 3: Fit a ridge regression model and visualize how coefficients change with lambda.\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import RidgeCV\n\n# Standardize the predictors\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Ridge regression with varying alphas\nalphas = np.logspace(-4, 4, 50) # reduced alphas for run time for time being\nridge = RidgeCV(alphas=alphas,  store_cv_results=True) # removing cv = , can't have both cv = and store_cv_results = True\n\nridge.fit(X_train_scaled, y_train)\n\n# Coefficients plot\nplt.figure(figsize=(10, 6))\nplt.plot(ridge.alphas, ridge.cv_results_.mean(axis=0).flatten(), label=\"CV Error\") # flattened cv results and updated to cv_results_ instead of cv_values_\nplt.xscale(\"log\")\nplt.xlabel(\"Lambda (Alpha)\")\nplt.ylabel(\"Cross-Validated MSE\")\nplt.title(\"Ridge Regression Coefficients vs. Lambda\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLasso Regression and Cross Validation Question 4 & 5: Fit lasso regression using LassoCV and interpret the results.\n\nfrom sklearn.linear_model import LassoCV\n\n# Lasso regression with cross-validation\nlasso = LassoCV(alphas=alphas, cv=10, random_state=42)\nlasso.fit(X_train_scaled,y_train.values.ravel()) # included .ravel to make 1D to avoid warning message \n\n# Plot Lasso results\nplt.figure(figsize=(10, 6))\nplt.plot(np.log10(lasso.alphas_), lasso.mse_path_.mean(axis=1), label=\"CV Error\")\nplt.xlabel(\"Log(Lambda)\")\nplt.ylabel(\"Cross-Validated MSE\")\nplt.title(\"Lasso Regression CV Results\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTuning and Model Comparison Question 6 & 7: Find the minimum MSE and associated lambda for both Ridge and Lass\n\n# Ridge results\nridge_min_mse = ridge.cv_results_.min() # changing cv_values_ to cv_results\nridge_best_alpha = ridge.alpha_\n\n# Lasso results\nlasso_min_mse = lasso.mse_path_.min()\nlasso_best_alpha = lasso.alpha_\n\nprint(f\"Ridge - Minimum MSE: {ridge_min_mse}, Best Alpha: {ridge_best_alpha}\")\nprint(f\"Lasso - Minimum MSE: {lasso_min_mse}, Best Alpha: {lasso_best_alpha}\")\n\nRidge - Minimum MSE: 3.6275260288369897e-10, Best Alpha: 0.12648552168552957\nLasso - Minimum MSE: 4.461505176426431, Best Alpha: 0.0013894954943731374\n\n\nQuestion 8: Use the “one-standard-error” rule and find the number of predictors in the Lasso model.\n\n# One-standard-error rule for Lasso\nlasso_best_alpha_1se = lasso.alphas_[np.where(\n    lasso.mse_path_.mean(axis=1) &lt;= (lasso.mse_path_.mean(axis=1).min() + lasso.mse_path_.std(axis=1).mean())\n)[0][0]]\n\nlasso_1se_model = Lasso(alpha=lasso_best_alpha_1se)\nlasso_1se_model.fit(X_train_scaled, y_train)\n\nprint(f\"Lasso 1-SE Rule Alpha: {lasso_best_alpha_1se}\")\nprint(f\"Number of Predictors in Lasso (1-SE): {np.sum(lasso_1se_model.coef_ != 0)}\")\n\nLasso 1-SE Rule Alpha: 1.2067926406393288\nNumber of Predictors in Lasso (1-SE): 3\n\n\nQuestion 9: Compare the performance of your Ridge and Lasso models."
  },
  {
    "objectID": "labs/Lab4/Lab4.html",
    "href": "labs/Lab4/Lab4.html",
    "title": "Lab 4: Fire and Tree Mortality",
    "section": "",
    "text": "# Lab 4 - Python Version\n\n# Imports\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n/Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n/Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n\n\n\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n/var/folders/zw/xpndwd1d7zn0v1tcw__xdbxw0000gn/T/ipykernel_94109/2838366582.py in &lt;module&gt;\n      7 from sklearn.linear_model import LogisticRegression\n      8 from sklearn.metrics import accuracy_score, confusion_matrix\n----&gt; 9 import statsmodels.api as sm\n     10 import matplotlib.pyplot as plt\n\n~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/api.py in &lt;module&gt;\n     25                                    ZeroInflatedGeneralizedPoisson,\n     26                                    ZeroInflatedNegativeBinomialP)\n---&gt; 27 from .tsa import api as tsa\n     28 from .duration.survfunc import SurvfuncRight\n     29 from .duration.hazard_regression import PHReg\n\n~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/api.py in &lt;module&gt;\n     29 from .vector_ar.vecm import VECM\n     30 from .vector_ar.svar_model import SVAR\n---&gt; 31 from .filters import api as filters\n     32 from . import tsatools\n     33 from .tsatools import (add_trend, detrend, lagmat, lagmat2ds, add_lag)\n\n~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/filters/api.py in &lt;module&gt;\n      4 from .hp_filter import hpfilter\n      5 from .cf_filter import cffilter\n----&gt; 6 from .filtertools import miso_lfilter, convolution_filter, recursive_filter\n\n~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/filters/filtertools.py in &lt;module&gt;\n     16 import scipy.fftpack as fft\n     17 from scipy import signal\n---&gt; 18 from scipy.signal.signaltools import _centered as trim_centered\n     19 \n     20 from statsmodels.tools.validation import array_like, PandasWrapper\n\nImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/Users/mateorobbins/opt/anaconda3/lib/python3.9/site-packages/scipy/signal/signaltools.py)\n\n\n\nThe database we’ll be working with today includes 36066 observations of individual trees involved in prescribed fires and wildfires occurring over 35 years, from 1981 to 2016. It is a subset of a larger fire and tree mortality database from the US Forest Service (see data description for the full database here: link). Our goal today is to predict the likelihood of tree mortality after a fire.\n\n# Data Exploration\n# Load the dataset\ntrees_dat = pd.read_csv(\"https://raw.githubusercontent.com/MaRo406/eds-232-machine-learning/main/data/trees-dat.csv\")\n\n# Quick overview of the data\nprint(trees_dat.head())\nprint(trees_dat.info())\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\n/var/folders/zw/xpndwd1d7zn0v1tcw__xdbxw0000gn/T/ipykernel_94109/3552313384.py in &lt;module&gt;\n      1 # Data Exploration\n      2 # Load the dataset\n----&gt; 3 trees_dat = pd.read_csv(\"https://raw.githubusercontent.com/MaRo406/eds-232-machine-learning/main/data/trees-dat.csv\")\n      4 \n      5 # Quick overview of the data\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)\n    209                 else:\n    210                     kwargs[new_arg_name] = new_arg_value\n--&gt; 211             return func(*args, **kwargs)\n    212 \n    213         return cast(F, wrapper)\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs)\n    329                     stacklevel=find_stack_level(),\n    330                 )\n--&gt; 331             return func(*args, **kwargs)\n    332 \n    333         # error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n    948     kwds.update(kwds_defaults)\n    949 \n--&gt; 950     return _read(filepath_or_buffer, kwds)\n    951 \n    952 \n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py in _read(filepath_or_buffer, kwds)\n    603 \n    604     # Create the parser.\n--&gt; 605     parser = TextFileReader(filepath_or_buffer, **kwds)\n    606 \n    607     if chunksize or iterator:\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py in __init__(self, f, engine, **kwds)\n   1440 \n   1441         self.handles: IOHandles | None = None\n-&gt; 1442         self._engine = self._make_engine(f, self.engine)\n   1443 \n   1444     def close(self) -&gt; None:\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py in _make_engine(self, f, engine)\n   1733                 if \"b\" not in mode:\n   1734                     mode += \"b\"\n-&gt; 1735             self.handles = get_handle(\n   1736                 f,\n   1737                 mode,\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    711 \n    712     # open URLs\n--&gt; 713     ioargs = _get_filepath_or_buffer(\n    714         path_or_buf,\n    715         encoding=encoding,\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py in _get_filepath_or_buffer(filepath_or_buffer, encoding, compression, mode, storage_options)\n    361         # assuming storage_options is to be interpreted as headers\n    362         req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n--&gt; 363         with urlopen(req_info) as req:\n    364             content_encoding = req.headers.get(\"Content-Encoding\", None)\n    365             if content_encoding == \"gzip\":\n\n~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py in urlopen(*args, **kwargs)\n    263     import urllib.request\n    264 \n--&gt; 265     return urllib.request.urlopen(*args, **kwargs)\n    266 \n    267 \n\n~/opt/anaconda3/lib/python3.9/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)\n    212     else:\n    213         opener = _opener\n--&gt; 214     return opener.open(url, data, timeout)\n    215 \n    216 def install_opener(opener):\n\n~/opt/anaconda3/lib/python3.9/urllib/request.py in open(self, fullurl, data, timeout)\n    521         for processor in self.process_response.get(protocol, []):\n    522             meth = getattr(processor, meth_name)\n--&gt; 523             response = meth(req, response)\n    524 \n    525         return response\n\n~/opt/anaconda3/lib/python3.9/urllib/request.py in http_response(self, request, response)\n    630         # request was successfully received, understood, and accepted.\n    631         if not (200 &lt;= code &lt; 300):\n--&gt; 632             response = self.parent.error(\n    633                 'http', request, response, code, msg, hdrs)\n    634 \n\n~/opt/anaconda3/lib/python3.9/urllib/request.py in error(self, proto, *args)\n    559         if http_err:\n    560             args = (dict, 'default', 'http_error_default') + orig_args\n--&gt; 561             return self._call_chain(*args)\n    562 \n    563 # XXX probably also want an abstract factory that knows when it makes\n\n~/opt/anaconda3/lib/python3.9/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args)\n    492         for handler in handlers:\n    493             func = getattr(handler, meth_name)\n--&gt; 494             result = func(*args)\n    495             if result is not None:\n    496                 return result\n\n~/opt/anaconda3/lib/python3.9/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs)\n    639 class HTTPDefaultErrorHandler(BaseHandler):\n    640     def http_error_default(self, req, fp, code, msg, hdrs):\n--&gt; 641         raise HTTPError(req.full_url, code, msg, hdrs, fp)\n    642 \n    643 class HTTPRedirectHandler(BaseHandler):\n\nHTTPError: HTTP Error 404: Not Found\n\n\n\n\n# Question 1: Recode predictors to zero-based integer form if categorical\nfor col in ['YrFireName', 'Species', 'Genus_species']:\n    trees_dat[col] = trees_dat[col].astype('category').cat.codes\n\n\n# Question 2: Data Splitting (70% training, 30% test)\ntrees_training, trees_test = train_test_split(trees_dat, test_size=0.3, random_state=42)\n\n# Question 3: Number of training observations\nprint(\"Training set observations:\", trees_training.shape[0])\n\n# Question 4: Correlation check for selecting top predictors\ncorrelations = trees_training.corr()['yr1status'].sort_values(ascending=False)\ntop_predictors = correlations.index[1:4]\nprint(\"Top predictors:\", top_predictors)\n\n# Question 5: Simple Logistic Regression for top predictors\nfor predictor in top_predictors:\n    X = trees_training[[predictor]]\n    y = trees_training['yr1status']\n    logit_model = sm.Logit(y, sm.add_constant(X)).fit()\n    print(f\"Logistic regression for predictor {predictor}:\\n\", logit_model.summary())\n\n# Question 6: Interpreting Coefficients - Output given in summaries above\n\n# Question 7: Visualize model fits\nfor predictor in top_predictors:\n    plt.figure()\n    plt.scatter(trees_training[predictor], trees_training['yr1status'], label='Data', alpha=0.5)\n    plt.xlabel(predictor)\n    plt.ylabel('yr1status')\n    plt.title(f'Logistic Fit - Predictor: {predictor}')\n    plt.show()\n\n# Question 8: Multiple Logistic Regression with all predictors\nX_full = trees_training[top_predictors]\ny_full = trees_training['yr1status']\nlogistic_full = sm.Logit(y_full, sm.add_constant(X_full)).fit()\nprint(\"Multiple logistic regression model:\\n\", logistic_full.summary())\n\n# Question 9: Cross-validation for model accuracy\nkf = KFold(n_splits=10, shuffle=True, random_state=42)\nmodels = [LogisticRegression() for _ in range(4)]  # Models for each top predictor and full model\n\nfor i, predictor in enumerate(list(top_predictors) + [top_predictors]):\n    X = trees_training[[predictor]] if isinstance(predictor, str) else trees_training[top_predictors]\n    y = trees_training['yr1status']\n    accuracy = cross_val_score(models[i], X, y, cv=kf, scoring='accuracy').mean()\n    print(f\"Cross-validated accuracy for model {i+1} ({predictor}): {accuracy}\")\n\n# Question 10: Highest accuracy identified in previous step\n\n# Question 11: Compute confusion matrix on most accurate model\nX_best = trees_training[top_predictors]  # assuming this is the best model\ny_best = trees_training['yr1status']\nmodel_best = LogisticRegression().fit(X_best, y_best)\ny_pred = model_best.predict(X_best)\nconf_matrix = confusion_matrix(y_best, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n# Question 12: Explain confusion matrix - Typically provides counts of TP, FP, TN, FN\n\n# Question 13: Overall model accuracy\naccuracy = accuracy_score(y_best, y_pred)\nprint(\"Model accuracy:\", accuracy)\n\n# Question 14: Test model on test data\nX_test = trees_test[top_predictors]\ny_test = trees_test['yr1status']\ny_test_pred = model_best.predict(X_test)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(\"Test accuracy:\", test_accuracy)\n\n# Question 15: Compare test accuracy to cross-validation accuracy\nprint(f\"Cross-validation accuracy: {accuracy}, Test accuracy: {test_accuracy}\")"
  },
  {
    "objectID": "sections.html",
    "href": "sections.html",
    "title": "Sections",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "sections.html#quarto",
    "href": "sections.html#quarto",
    "title": "Sections",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "sections.html#running-code",
    "href": "sections.html#running-code",
    "title": "Sections",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "sections/week0.html",
    "href": "sections/week0.html",
    "title": "week0",
    "section": "",
    "text": "This will contain content to support students in creating a notebook for the week’s section material.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "sections/week0.html#test-section-page",
    "href": "sections/week0.html#test-section-page",
    "title": "week0",
    "section": "",
    "text": "This will contain content to support students in creating a notebook for the week’s section material.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "discussion/week0.html",
    "href": "discussion/week0.html",
    "title": "week0",
    "section": "",
    "text": "This will contain content to support students in creating a notebook for the week’s section material.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "discussion/week0.html#test-section-page",
    "href": "discussion/week0.html#test-section-page",
    "title": "week0",
    "section": "",
    "text": "This will contain content to support students in creating a notebook for the week’s section material.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Algorithm Selection Guidance\n\n\nAnimated Explainers\nhttps://mlu-explain.github.io/bias-variance/ https://bbest.github.io/eds232-ml/resources.html\n\n\nLiterature\n\n\nContext for Weekly Labs\n\n\nMachine Learning in Environmental Science\nMachine Learning for Ecology and Sustainable Natural Resource Management https://link.springer.com/book/10.1007/978-3-319-96978-7\nMachine Learning in Wildlife Biology: Algorithms, Data Issues and Availability, Workflows, Citizen Science, Code Sharing, Metadata and a Brief Historical Perspective\n\n\nKey ML Papers and Empirical Foundation of Heuristics\n- 1 SE rule - 70/30 Split\n- Data Primacy\n- All you need is attention"
  }
]