{
  "articles": [
    {
      "path": "assignments.html",
      "title": "Assignments",
      "author": [],
      "contents": "\n\nContents\nWeek 1\nSlides:\nAssigned\nReading:\nSupplementary Reading:\nLab:\n\nWeek 2\nSlides:\nAssigned\nReading:\nLab:\n\nWeek 3\nSlides:\nAssigned\nReading:\nSupplementary Reading:\nLab:\n\nWeek 4\nSlides:\nAssigned\nReading:\nSupplementary Reading:\nLab:\nWeek 5\nSlides:\nAssigned\nReading:\nSupplementary Reading:\nLab:\nWeek 6\nSlides:\nAssigned\nReading:\nSupplementary Reading:\nLab:\nWeek 7\nSlides:\nAssigned\nReading:\nSupplementary Reading:\nLab:\n\n\n\nAssigned readings and labs will be posted to this page on a weekly\nbasis.\n\nWeek 1\nSlides:\nLecture 1: Course\nWelcome and Intro\nLecture 2: Linear\nregression I\nAssigned Reading:\nHOML Ch.\n1 (1.1 - 1.4)\nSupplementary Reading:\nStatistical\nModeling: The Two Cultures\nLab:\nLink\nto .Rmd\nWeek 2\nSlides:\nLecture: Linear\nRegression II\nAssigned Reading:\nHOML\nCh. 2 (4.2-4.5)\nReview of basic regression. Feel free to skim this a bit if you feel\ngood about your understanding of linear regression.\n\nTidy\nModels in R Ch. 3 (3.3-3.5)\nIntro to Tidy Modeling. Provides some context for Lab 1 and\nbeyond.\n\nLab:\nLink\nto .Rmd\nWeek 3\nSlides:\nLecture: Model\nProcess and Regularized Regression\nAssigned Reading:\nHOML\nCh. 6\nSupplementary Reading:\nBias-Variance\nScrollytelling\nGagne et\nal. (2018)\nLab:\nLink\nto the Lab 3 Demo\nLink\nto the Lab 3 Assignment\nWeek 4\nSlides:\nLecture: Classification\nand Logistic Regression\nAssigned Reading:\nHOML\nCh. 5\nSupplementary Reading:\nThese will help you with Lab 4.\nHOML\nCh. 2.6\nCansler et\nal. 2020: Fire Tree Mortality Database paper\nLab:\nLink\nto the Lab 4 Demo\nLink\nto Lab 4 Assignment\nWeek 5\nSlides:\nLecture: k-Nearest\nNeighbors and Decision Trees\nAssigned Reading:\nHOML Ch.\n8,9,10\nSupplementary Reading:\nDecision\ntree scrollytelling - cool visualization of decision trees – check\nit out!\nLab:\nLink\nto the Lab 5 Demo\nLab\n5 – Updated\nWeek 6\nSlides:\nLecture: Bagging\nand Random Forests\nAssigned Reading:\nHOML Ch.\n11\nSupplementary Reading:\nLab:\nLab\n5 Demo part 2\nWeek 7\nSlides:\nGuest Lecture\nAssigned Reading:\nMcGovern\net al. (2022)\nSupplementary Reading:\nLab:\nNo lab this week\n\n\n\n",
      "last_modified": "2023-02-20T11:50:10-08:00"
    },
    {
      "path": "index.html",
      "title": "EDS 232: Machine Learning in Environmental Science",
      "description": "",
      "author": [],
      "contents": "\n\nContents\nWelcome to the EDS 232\nwebsite\nCourse\ndescription\nTeaching\nteam\nImportant\nlinks\nWeekly course schedule\nLearning\nobjectives\nCourse\nrequirements\nComputing\nTextbook\n\n\nTentative\ntopics\n\n\n\n\nFigure 1: Image created using the Midjourney image\ngeneration tool\n\n\n\nWelcome to the EDS 232\nwebsite\nCourse description\nMachine learning is a field of inquiry devoted to understanding and\nbuilding methods that ‘learn’, that is, methods that leverage data to\nimprove performance on some set of tasks. In this course, we focus on\nthe core concepts of machine learning that beginning ML researchers must\nknow. We cover ‘classical machine learning’ primarily using R, and\nexplore applications to environmental science. To understand broader\nconcepts of artificial intelligence or deep learning, a strong\nfundamental knowledge of machine learning is indispensable.\nTeaching team\nInstructor: Mateo Robbins (mjrobbins@ucsb.edu)\nOffice: NCEAS Group Office\nOffice hours: Monday 11:00-12:00\nTeaching assistant: Brian Lee\n(brianlee52@bren.ucsb.edu)\nOffice: Bren Hall Room 1001\nOffice hours: Thursday 11:00-12:00\nImportant links\nLink\nto full course syllabus\nWeekly course schedule\nLectures: M, W 9:30 - 10:45am PST (NCEAS)\nLearning objectives\nThe goal of EDS 232 is to equip students with a strong foundation in\nthe core concepts of machine learning. By the end of the course,\nstudents should be able to: \nBuild machine learning models in R using popular machine learning\npackages\nBuild and train supervised machine learning models for prediction\nand binary classification tasks, including linear and logistic\nregression.\nApply best practices for machine learning development so that\nyour models generalize to data and tasks in the real world.\nBuild and use decision trees and tree ensemble methods, including\nrandom forests and boosted trees.\nUse unsupervised learning techniques for unsupervised learning:\nincluding clustering.\nCourse requirements\nComputing\nMinimum\nMEDS device requirements\nR version 4.0.2 (or higher)\nRStudio version 1.4.1103 (or higher)\nTextbook\nHands-On Machine\nLearning with R, by Bradley Boehmke and Brandon Greenwell\n\nTentative topics\nWeek #\nDates\nLecture \n1\n1/9, 1/11\nIntroduction, Linear Regression and ML Modeling Fundamentals I\n2\nMLK, 1/18\nLinear Regression and ML Modeling Fundamentals II\n3\n1/23, 1/25\nRegularized Regression\n4\n1/30, 2/1\nLogistic Regression, Classification\n5\n2/6, 2/8\nK-nearest Neighbors, Decision Trees\n6\n2/13, 2/15\nRandom Forests\n7\nPresidents, 2/22\nEthics, Justice, Bias – Guest Speaker\n8\n2/27, 3/1\nGradient Boosting\n9\n3/6, 3/8\nClustering\n10\n3/13, 3/15\nDeep Learning or Support Vectors\n\n\n\n",
      "last_modified": "2023-02-16T17:50:20-08:00"
    },
    {
      "path": "resources.html",
      "title": "Course resources",
      "author": [],
      "contents": "\n\nContents\nWeek 1\n\n\nTO UPDATE THIS PAGE: Open and edit the resources.Rmd file,\nin the project root, to delete this placeholder text and customize with\nyour own!\n\nWeek 1\nLecture slides: Assignment:\n\n\n\n",
      "last_modified": "2023-01-12T11:43:33-08:00"
    },
    {
      "path": "topic_1.html",
      "title": "Course Resources",
      "author": [],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nWeek 1\n\nWeek 1\nSlides\nRegression I\n\nAssigned Reading\nHOML Ch.\n1\n\nLab\nSupplementary Reading\n\n\n\n",
      "last_modified": "2023-01-18T00:39:06-08:00"
    }
  ],
  "collections": []
}
